## scoring = 'f1'
Best parameters for Gaussian Naive Bayes are : 
{'priors': None, 'var_smoothing': 1e-09} 
 f1= 0.5517241379310345,             precision: 0.6666666666666666, recall= 0.47058823529411764
 ****************************
 Best parameters for Decision Tree  are : 
{'class_weight': None, 'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 13, 'splitter': 'random'} 
 f1= 0.29629629629629634,             precision: 0.4, recall= 0.23529411764705882
 ****************************
 Best parameters for Neural Networks are : 
{'activation': 'tanh', 'learning_rate': 'constant', 'shuffle': True, 'solver': 'lbfgs'} 
 f1= 0.33333333333333337,             precision: 0.38461538461538464, recall= 0.29411764705882354
 ****************************
 Best parameters for Random Forest are : 
{'bootstrap': True, 'criterion': 'gini', 'max_features': 'auto', 'min_samples_split': 3, 'n_estimators': 100} 
 f1= 0.5999999999999999,             precision: 0.6923076923076923, recall= 0.5294117647058824
 ****************************
 Best parameters for Support Vector Machine (linear) are : 
{'C': 3.0, 'loss': 'squared_hinge', 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'l2'} 
 f1= 0.1111111111111111,             precision: 1.0, recall= 0.058823529411764705
 ****************************




 ## scoring = 'accuracy'
 Best parameters for Gaussian Naive Bayes are : 
{'priors': None, 'var_smoothing': 1e-09} 
 f1= 0.4285714285714286,             precision: 0.34615384615384615, recall= 0.5625
 ****************************
 Best parameters for Decision Tree  are : 
{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 3, 'splitter': 'random'} 
 f1= 0.1111111111111111,             precision: 0.5, recall= 0.0625
 ****************************
 Best parameters for Neural Networks are : 
{'activation': 'logistic', 'learning_rate': 'constant', 'shuffle': False, 'solver': 'adam'} 
 f1= 0.4827586206896552,             precision: 0.5384615384615384, recall= 0.4375
 ****************************
 Best parameters for Random Forest are : 
{'bootstrap': True, 'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_split': 3, 'n_estimators': 100} 
 f1= 0.42857142857142855,             precision: 0.5, recall= 0.375
 ****************************
 Best parameters for Support Vector Machine (linear) are : 
{'C': 4.0, 'loss': 'squared_hinge', 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'l2'} 
 f1= 0.3333333333333333,             precision: 0.5, recall= 0.25
 ****************************


 ## scoring = 'balanced_accuracy'

Best parameters for Gaussian Naive Bayes are : 
{'priors': None, 'var_smoothing': 1e-07} 
 f1= 0.42424242424242425,             precision: 0.4666666666666667, recall= 0.3888888888888889
 ****************************
 Best parameters for Decision Tree  are : 
{'class_weight': None, 'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 18, 'splitter': 'random'} 
 f1= 0.5142857142857143,             precision: 0.5294117647058824, recall= 0.5
 ****************************
 Best parameters for Neural Networks are : 
{'activation': 'relu', 'learning_rate': 'adaptive', 'shuffle': True, 'solver': 'adam'} 
 f1= 0.45161290322580644,             precision: 0.5384615384615384, recall= 0.3888888888888889
 ****************************
 Best parameters for Random Forest are : 
{'bootstrap': True, 'criterion': 'gini', 'max_features': 'log2', 'min_samples_split': 3, 'n_estimators': 100} 
 f1= 0.43750000000000006,             precision: 0.5, recall= 0.3888888888888889
 ****************************
 Best parameters for Support Vector Machine (linear) are : 
{'C': 1.0, 'loss': 'squared_hinge', 'max_iter': 2000, 'multi_class': 'crammer_singer', 'penalty': 'l1'} 
 f1= 0.391304347826087,             precision: 0.24324324324324326, recall= 1.0
 ****************************

 ## scoring= 'f1_weighted'
 Best parameters for Gaussian Naive Bayes are : 
{'priors': None, 'var_smoothing': 1e-07} 
 f1= 0.41379310344827586,             precision: 0.6666666666666666, recall= 0.3
 ****************************
 Best parameters for Decision Tree  are : 
{'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 9, 'splitter': 'best'} 
 f1= 0.24999999999999997,             precision: 0.75, recall= 0.15
 ****************************
 Best parameters for Neural Networks are : 
{'activation': 'tanh', 'learning_rate': 'constant', 'shuffle': True, 'solver': 'adam'} 
 f1= 0.16000000000000003,             precision: 0.4, recall= 0.1
 ****************************
 Best parameters for Random Forest are : 
{'bootstrap': True, 'criterion': 'gini', 'max_features': 'auto', 'min_samples_split': 3, 'n_estimators': 100} 
 f1= 0.35714285714285715,             precision: 0.625, recall= 0.25
 ****************************
 Best parameters for Support Vector Machine (linear) are : 
{'C': 1.0, 'loss': 'hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2'} 
 f1= 0.09523809523809523,             precision: 1.0, recall= 0.05
 ****************************
 
 ## scoring = top_k_accuracy

 Best parameters for Gaussian Naive Bayes are : 
{'priors': None, 'var_smoothing': 1e-09} 
 f1= 0.4,             precision: 0.5, recall= 0.3333333333333333
 ****************************
 Best parameters for Decision Tree  are : 
{'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'splitter': 'best'} 
 f1= 0.3448275862068965,             precision: 0.35714285714285715, recall= 0.3333333333333333
 ****************************
 Best parameters for Neural Networks are : 
{'activation': 'identity', 'learning_rate': 'constant', 'shuffle': True, 'solver': 'lbfgs'} 
 f1= nan,             precision: 0.0, recall= 0.0
 ****************************
 Best parameters for Random Forest are : 
{'bootstrap': True, 'criterion': 'gini', 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 100} 
 f1= 0.47619047619047616,             precision: 0.8333333333333334, recall= 0.3333333333333333
 ****************************
 Best parameters for Support Vector Machine (linear) are : 
{'C': 1.0, 'loss': 'hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2'} 
 f1= 0.11764705882352941,             precision: 0.5, recall= 0.06666666666666667
 ****************************




 
 Best parameters for Gaussian Naive Bayes are : 
{'priors': None, 'var_smoothing': 1e-09} 
 f1= 0.47058823529411764,             precision: 0.5, recall= 0.4444444444444444
 ****************************
 Best parameters for Decision Tree  are : 
{'class_weight': None, 'criterion': 'gini', 'max_depth': 28, 'min_samples_split': 28, 'splitter': 'random'} 
 f1= 0.5142857142857143,             precision: 0.5294117647058824, recall= 0.5
 ****************************
 Best parameters for Neural Networks are : 
{'activation': 'relu', 'learning_rate': 'constant', 'shuffle': True, 'solver': 'sgd'} 
 f1= 0.21428571428571427,             precision: 0.3, recall= 0.16666666666666666
 ****************************
 Best parameters for Random Forest are : 
{'bootstrap': False, 'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_split': 4, 'n_estimators': 100} 
 f1= 0.5806451612903226,             precision: 0.6923076923076923, recall= 0.5
 ****************************
 Best parameters for Support Vector Machine (linear) are : 
{'C': 2.0, 'loss': 'hinge', 'max_iter': 2000, 'multi_class': 'crammer_singer', 'penalty': 'l2'} 
 f1= 0.380952380952381,             precision: 0.3333333333333333, recall= 0.4444444444444444
 ****************************
 

 
 Best parameters for Gaussian Naive Bayes are : 
{'priors': None, 'var_smoothing': 1e-09} 
 f1= 0.42857142857142855,             precision: 0.42857142857142855, recall= 0.42857142857142855
 ****************************
 Best parameters for Decision Tree  are : 
{'class_weight': None, 'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 28, 'splitter': 'random'} 
 f1= 0.4324324324324324,             precision: 0.5, recall= 0.38095238095238093
 ****************************
 Best parameters for Neural Networks are : 
{'activation': 'tanh', 'learning_rate': 'invscaling', 'shuffle': True, 'solver': 'lbfgs'} 
 f1= 0.31249999999999994,             precision: 0.45454545454545453, recall= 0.23809523809523808
 ****************************
 Best parameters for Random Forest are : 
{'bootstrap': True, 'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_split': 3, 'n_estimators': 100} 
 f1= 0.4242424242424242,             precision: 0.5833333333333334, recall= 0.3333333333333333
 ****************************
 Best parameters for Support Vector Machine (linear) are : 
{'C': 3.0, 'loss': 'hinge', 'max_iter': 2000, 'multi_class': 'crammer_singer', 'penalty': 'l1'} 
 f1= 0.3584905660377359,             precision: 0.2235294117647059, recall= 0.9047619047619048
 ****************************
 